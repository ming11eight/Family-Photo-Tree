{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--image_size IMAGE_SIZE] [--margin MARGIN]\n",
      "                             [--min_cluster_size MIN_CLUSTER_SIZE]\n",
      "                             [--cluster_threshold CLUSTER_THRESHOLD]\n",
      "                             [--largest_cluster_only]\n",
      "                             [--gpu_memory_fraction GPU_MEMORY_FRACTION]\n",
      "                             model data_dir out_dir\n",
      "ipykernel_launcher.py: error: the following arguments are required: model, data_dir, out_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/1qqqaa1/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2017 PXL University College\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Clusters similar faces from input folder together in folders based on euclidean distance matrix\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from scipy import misc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import facenet\n",
    "import align.detect_face\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    pnet, rnet, onet = create_network_face_detection(args.gpu_memory_fraction)\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            facenet.load_model(args.model)\n",
    "\n",
    "            image_list = load_images_from_folder(args.data_dir)\n",
    "            images = align_data(image_list, args.image_size, args.margin, pnet, rnet, onet)\n",
    "\n",
    "            images_placeholder = sess.graph.get_tensor_by_name(\"input:0\")\n",
    "            embeddings = sess.graph.get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = sess.graph.get_tensor_by_name(\"phase_train:0\")\n",
    "            feed_dict = {images_placeholder: images, phase_train_placeholder: False}\n",
    "            emb = sess.run(embeddings, feed_dict=feed_dict)\n",
    "\n",
    "            nrof_images = len(images)\n",
    "\n",
    "            matrix = np.zeros((nrof_images, nrof_images))\n",
    "\n",
    "            print('')\n",
    "            # Print distance matrix\n",
    "            print('Distance matrix')\n",
    "            print('    ', end='')\n",
    "            for i in range(nrof_images):\n",
    "                print('    %1d     ' % i, end='')\n",
    "            print('')\n",
    "            for i in range(nrof_images):\n",
    "                print('%1d  ' % i, end='')\n",
    "                for j in range(nrof_images):\n",
    "                    dist = np.sqrt(np.sum(np.square(np.subtract(emb[i, :], emb[j, :]))))\n",
    "                    matrix[i][j] = dist\n",
    "                    print('  %1.4f  ' % dist, end='')\n",
    "                print('')\n",
    "\n",
    "            print('')\n",
    "\n",
    "            # DBSCAN is the only algorithm that doesn't require the number of clusters to be defined.\n",
    "            db = DBSCAN(eps=args.cluster_threshold, min_samples=args.min_cluster_size, metric='precomputed')\n",
    "            db.fit(matrix)\n",
    "            labels = db.labels_\n",
    "\n",
    "            # get number of clusters\n",
    "            no_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "            print('No of clusters:', no_clusters)\n",
    "\n",
    "            if no_clusters > 0:\n",
    "                if args.largest_cluster_only:\n",
    "                    largest_cluster = 0\n",
    "                    for i in range(no_clusters):\n",
    "                        print('Cluster {}: {}'.format(i, np.nonzero(labels == i)[0]))\n",
    "                        if len(np.nonzero(labels == i)[0]) > len(np.nonzero(labels == largest_cluster)[0]):\n",
    "                            largest_cluster = i\n",
    "                    print('Saving largest cluster (Cluster: {})'.format(largest_cluster))\n",
    "                    cnt = 1\n",
    "                    for i in np.nonzero(labels == largest_cluster)[0]:\n",
    "                        misc.imsave(os.path.join(args.out_dir, str(cnt) + '.png'), images[i])\n",
    "                        cnt += 1\n",
    "                else:\n",
    "                    print('Saving all clusters')\n",
    "                    for i in range(no_clusters):\n",
    "                        cnt = 1\n",
    "                        print('Cluster {}: {}'.format(i, np.nonzero(labels == i)[0]))\n",
    "                        path = os.path.join(args.out_dir, str(i))\n",
    "                        if not os.path.exists(path):\n",
    "                            os.makedirs(path)\n",
    "                            for j in np.nonzero(labels == i)[0]:\n",
    "                                misc.imsave(os.path.join(path, str(cnt) + '.png'), images[j])\n",
    "                                cnt += 1\n",
    "                        else:\n",
    "                            for j in np.nonzero(labels == i)[0]:\n",
    "                                misc.imsave(os.path.join(path, str(cnt) + '.png'), images[j])\n",
    "                                cnt += 1\n",
    "\n",
    "\n",
    "def align_data(image_list, image_size, margin, pnet, rnet, onet):\n",
    "    minsize = 20  # minimum size of face\n",
    "    threshold = [0.6, 0.7, 0.7]  # three steps's threshold\n",
    "    factor = 0.709  # scale factor\n",
    "\n",
    "    img_list = []\n",
    "\n",
    "    for x in range(len(image_list)):\n",
    "        img_size = np.asarray(image_list[x].shape)[0:2]\n",
    "        bounding_boxes, _ = align.detect_face.detect_face(image_list[x], minsize, pnet, rnet, onet, threshold, factor)\n",
    "        nrof_samples = len(bounding_boxes)\n",
    "        if nrof_samples > 0:\n",
    "            for i in range(nrof_samples):\n",
    "                if bounding_boxes[i][4] > 0.95:\n",
    "                    det = np.squeeze(bounding_boxes[i, 0:4])\n",
    "                    bb = np.zeros(4, dtype=np.int32)\n",
    "                    bb[0] = np.maximum(det[0] - margin / 2, 0)\n",
    "                    bb[1] = np.maximum(det[1] - margin / 2, 0)\n",
    "                    bb[2] = np.minimum(det[2] + margin / 2, img_size[1])\n",
    "                    bb[3] = np.minimum(det[3] + margin / 2, img_size[0])\n",
    "                    cropped = image_list[x][bb[1]:bb[3], bb[0]:bb[2], :]\n",
    "                    aligned = misc.imresize(cropped, (image_size, image_size), interp='bilinear')\n",
    "                    prewhitened = facenet.prewhiten(aligned)\n",
    "                    img_list.append(prewhitened)\n",
    "\n",
    "    if len(img_list) > 0:\n",
    "        images = np.stack(img_list)\n",
    "        return images\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_network_face_detection(gpu_memory_fraction):\n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n",
    "    return pnet, rnet, onet\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = misc.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "def parse_arguments(argv):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('model', type=str, default='./log/best_state.pth'\n",
    "                        help='Either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file')\n",
    "    parser.add_argument('data_dir', type=str, \n",
    "                        help='The directory containing the images to cluster into folders.')\n",
    "    parser.add_argument('out_dir', type=str,\n",
    "                        help='The output directory where the image clusters will be saved.')\n",
    "    parser.add_argument('--image_size', type=int,\n",
    "                        help='Image size (height, width) in pixels.', default=160)\n",
    "    parser.add_argument('--margin', type=int,\n",
    "                        help='Margin for the crop around the bounding box (height, width) in pixels.', default=44)\n",
    "    parser.add_argument('--min_cluster_size', type=int,\n",
    "                        help='The minimum amount of pictures required for a cluster.', default=1)\n",
    "    parser.add_argument('--cluster_threshold', type=float,\n",
    "                        help='The minimum distance for faces to be in the same cluster', default=1.0)\n",
    "    parser.add_argument('--largest_cluster_only', action='store_true',\n",
    "                        help='This argument will make that only the biggest cluster is saved.')\n",
    "    parser.add_argument('--gpu_memory_fraction', type=float,\n",
    "                        help='Upper bound on the amount of GPU memory that will be used by the process.', default=1.0)\n",
    "\n",
    "    return parser.parse_args(argv)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(parse_arguments(sys.argv[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting facenet\n",
      "  Downloading facenet-1.0.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from facenet) (1.7.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from facenet) (2.28.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from facenet) (1.0.2)\n",
      "Requirement already satisfied: psutil in /home/1qqqaa1/.local/lib/python3.7/site-packages (from facenet) (5.9.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from facenet) (3.5.3)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (from facenet) (2.11.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from facenet) (9.3.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from facenet) (3.8.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from facenet) (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from h5py->facenet) (1.21.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->facenet) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->facenet) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/1qqqaa1/.local/lib/python3.7/site-packages (from matplotlib->facenet) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/1qqqaa1/.local/lib/python3.7/site-packages (from matplotlib->facenet) (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->facenet) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->facenet) (4.38.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->facenet) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->facenet) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->facenet) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->facenet) (3.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->facenet) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->facenet) (3.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (2.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (65.5.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (3.3.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/1qqqaa1/.local/lib/python3.7/site-packages (from tensorflow->facenet) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (2.11.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (15.0.6.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (0.30.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (2.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (23.1.21)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (1.14.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (1.51.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (3.19.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow->facenet) (4.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow->facenet) (0.38.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->facenet) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->facenet) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->facenet) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->facenet) (2.15.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->facenet) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->facenet) (3.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->facenet) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->facenet) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->facenet) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->facenet) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->facenet) (5.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow->facenet) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->facenet) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->facenet) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->facenet) (3.2.2)\n",
      "Installing collected packages: facenet\n",
      "Successfully installed facenet-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install facenet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
